[the metamorphic testing paper] metamorphic testing, which checks that, if a property holds on a pair of inputs, a test property holds on the outputs. For example, for certain ML models (e.g., SVM), a valid metamorphic test would check that, if two datasets are permutations of each other (i.e, they differ only in the order of training examples), then the outputs should be equal. This paper focuses on SVM and ResNet models written in TensorFlow. Using MutPy, a framework that systematically mutates Python programs for testing purposes, the authors injected bugs into the models to find with metamorphic testing.

[CRADLE paper] uses differential testing between two ML model implementations (i.e., 2 frameworks) to identify and localize performance-affecting anomalies. The system searches labelled validation instances (test data) from public datasets to identify inconsistencies between the execution trees of the two implementations. Autoduff doesn't depend on public data, instead using blackbox fuzzing to search for inconsistency-producing inputs.

[STORM paper] combines integration testing with a program reduction technique in order to approximate "smallest reproducible examples" for bugs, thereby aiding bug localization efforts.
